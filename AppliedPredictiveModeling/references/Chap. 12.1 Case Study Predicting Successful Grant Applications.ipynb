{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'English_United States.1252'"
      ],
      "text/latex": [
       "'English\\_United States.1252'"
      ],
      "text/markdown": [
       "'English_United States.1252'"
      ],
      "text/plain": [
       "[1] \"English_United States.1252\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chr [1:1073] \"NumCI\" \"NumDR\" \"NumECI\" \"NumEA\" \"NumHV\" \"NumPS\" \"NumSCI\" ...\n",
      " chr [1:252] \"NumCI\" \"NumDR\" \"NumECI\" \"NumPS\" \"NumSCI\" \"NumSR\" \"NumUNK\" ...\n"
     ]
    }
   ],
   "source": [
    "# 12.1 Case Study: Predicting Successful Grant Applications\n",
    "Sys.setlocale(\"LC_TIME\", \"English\")\n",
    "\n",
    "library(parallel)\n",
    "setDefaultCluster(makeCluster(4))\n",
    "source('CreateGrantData.R')\n",
    "save(training,testing,pre2008,fullSet,reducedSet,file = \"grant_Data.Rdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`there are 1073 predictors in fullSet, However the book show only 1070 predictors @page 311`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'trimmedmat'</li>\n",
       "\t<li>'numbers.discarded'</li>\n",
       "\t<li>'names.discarded'</li>\n",
       "\t<li>'size'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'trimmedmat'\n",
       "\\item 'numbers.discarded'\n",
       "\\item 'names.discarded'\n",
       "\\item 'size'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'trimmedmat'\n",
       "2. 'numbers.discarded'\n",
       "3. 'names.discarded'\n",
       "4. 'size'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"trimmedmat\"        \"numbers.discarded\" \"names.discarded\"  \n",
       "[4] \"size\"             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reducedCovMat <- cov(training[,reducedSet])\n",
    "library(subselect)\n",
    "trimmingResults <- trim.matrix(reducedCovMat)\n",
    "names(trimmingResults)\n",
    "trimmingResults$names.discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'NumDR'</li>\n",
       "\t<li>'PS.1975'</li>\n",
       "\t<li>'CI.Dept1798'</li>\n",
       "\t<li>'PS.Dept3028'</li>\n",
       "\t<li>'PS.Faculty1'</li>\n",
       "\t<li>'BTotal'</li>\n",
       "\t<li>'numPeople'</li>\n",
       "\t<li>'Apr'</li>\n",
       "\t<li>'Sun'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'NumDR'\n",
       "\\item 'PS.1975'\n",
       "\\item 'CI.Dept1798'\n",
       "\\item 'PS.Dept3028'\n",
       "\\item 'PS.Faculty1'\n",
       "\\item 'BTotal'\n",
       "\\item 'numPeople'\n",
       "\\item 'Apr'\n",
       "\\item 'Sun'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'NumDR'\n",
       "2. 'PS.1975'\n",
       "3. 'CI.Dept1798'\n",
       "4. 'PS.Dept3028'\n",
       "5. 'PS.Faculty1'\n",
       "6. 'BTotal'\n",
       "7. 'numPeople'\n",
       "8. 'Apr'\n",
       "9. 'Sun'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"NumDR\"       \"PS.1975\"     \"CI.Dept1798\" \"PS.Dept3028\" \"PS.Faculty1\"\n",
       "[6] \"BTotal\"      \"numPeople\"   \"Apr\"         \"Sun\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#apply to full set\n",
    "fullCovMat <- cov(training[,fullSet])\n",
    "fullSetResults <- trim.matrix(fullCovMat)\n",
    "fullSetResults$names.discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"grantData.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'successful'</li>\n",
       "\t<li>'unsuccessful'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'successful'\n",
       "\\item 'unsuccessful'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'successful'\n",
       "2. 'unsuccessful'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"successful\"   \"unsuccessful\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "levels(training$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  glm(formula = Class ~ Day, family = binomial, data = training[pre2008, \n",
       "    ])\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)          Day  \n",
       "    -0.3660       0.0267  \n",
       "\n",
       "Degrees of Freedom: 6632 Total (i.e. Null);  6631 Residual\n",
       "Null Deviance:\t    9191 \n",
       "Residual Deviance: 9103 \tAIC: 9107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(caret)\n",
    "fit_glt <- glm(Class~Day,\n",
    "              data=training[pre2008,],\n",
    "              family=binomial)\n",
    "fit_glt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>0.52473469808025</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>0.025616506736391</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>0.000479097987638677</dd>\n",
       "\t<dt>4</dt>\n",
       "\t\t<dd>0.000126141649641753</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 0.52473469808025\n",
       "\\item[2] 0.025616506736391\n",
       "\\item[3] 0.000479097987638677\n",
       "\\item[4] 0.000126141649641753\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   0.524734698080252\n",
       ":   0.0256165067363913\n",
       ":   0.0004790979876386774\n",
       ":   0.000126141649641753\n",
       "\n"
      ],
      "text/plain": [
       "           1            2            3            4 \n",
       "0.5247346981 0.0256165067 0.0004790980 0.0001261416 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "successProb <- 1- predict(\n",
    "                          fit_glt,\n",
    "                          newdata = data.frame(Day=c(10,150,300,350)),\n",
    "                         type=\"response\")\n",
    "\n",
    "successProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  glm(formula = Class ~ Day + I(Day^2), family = binomial, data = training[pre2008, \n",
       "    ])\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)          Day     I(Day^2)  \n",
       "  -1.050342     0.165185    -0.004645  \n",
       "\n",
       "Degrees of Freedom: 6632 Total (i.e. Null);  6630 Residual\n",
       "Null Deviance:\t    9191 \n",
       "Residual Deviance: 8903 \tAIC: 8909"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_daySquared <- glm(\n",
    "                      Class~Day + I(Day^2),\n",
    "                     data=training[pre2008,],\n",
    "                     family=binomial)\n",
    "fit_daySquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Logistic Regression Model\n",
       " \n",
       " lrm(formula = Class ~ rcs(Day), data = training[pre2008, ])\n",
       " \n",
       "                       Model Likelihood     Discrimination    Rank Discrim.    \n",
       "                          Ratio Test           Indexes           Indexes       \n",
       " Obs          6633    LR chi2     324.93    R2       0.064    C       0.596    \n",
       "  successful  3233    d.f.             4    g        0.453    Dxy     0.192    \n",
       "  unsuccessful3400    Pr(> chi2) <0.0001    gr       1.573    gamma   0.204    \n",
       " max |deriv| 1e-10                          gp       0.108    tau-a   0.096    \n",
       "                                            Brier    0.238                     \n",
       " \n",
       "           Coef    S.E.   Wald Z Pr(>|Z|)\n",
       " Intercept -1.2946 0.0894 -14.48 <0.0001 \n",
       " Day        0.2316 0.0183  12.67 <0.0001 \n",
       " Day'      -0.7221 0.0825  -8.76 <0.0001 \n",
       " Day''      2.5730 0.3564   7.22 <0.0001 \n",
       " Day'''    -4.7924 0.8021  -5.97 <0.0001 \n",
       " "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(rms)\n",
    "fit_rcs <- lrm(Class~rcs(Day),data=training[pre2008,])\n",
    "fit_rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "31"
      ],
      "text/latex": [
       "31"
      ],
      "text/markdown": [
       "31"
      ],
      "text/plain": [
       "[1] 31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max(training[pre2008,'Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAgP9NTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dayProfile <- Predict(fit_rcs,Day=0:365,fun=function(x)-x)\n",
    "plot(dayProfile,ylab=\"Log Odds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "### Section 12.1 Case Study: Predicting Successful Grant Applications\n",
    "\n",
    "load(\"grantData.RData\")\n",
    "\n",
    "library(caret)\n",
    "library(doMC)\n",
    "registerDoMC(12)\n",
    "library(plyr)\n",
    "library(reshape2)\n",
    "\n",
    "## Look at two different ways to split and resample the data. A support vector\n",
    "## machine is used to illustrate the differences. The full set of predictors\n",
    "## is used. \n",
    "\n",
    "pre2008Data <- training[pre2008,]\n",
    "year2008Data <- rbind(training[-pre2008,], testing)\n",
    "\n",
    "set.seed(552)\n",
    "test2008 <- createDataPartition(year2008Data$Class, p = .25)[[1]]\n",
    "\n",
    "allData <- rbind(pre2008Data, year2008Data[-test2008,])\n",
    "holdout2008 <- year2008Data[test2008,]\n",
    "\n",
    "## Use a common tuning grid for both approaches. \n",
    "svmrGrid <- expand.grid(sigma = c(.00007, .00009, .0001, .0002),\n",
    "                        C = 2^(-3:8))\n",
    "\n",
    "## Evaluate the model using overall 10-fold cross-validation\n",
    "ctrl0 <- trainControl(method = \"cv\",\n",
    "                      summaryFunction = twoClassSummary,\n",
    "                      classProbs = TRUE)\n",
    "set.seed(477)\n",
    "svmFit0 <- train(pre2008Data[,fullSet], pre2008Data$Class,\n",
    "                 method = \"svmRadial\",\n",
    "                 tuneGrid = svmrGrid,\n",
    "                 preProc = c(\"center\", \"scale\"),\n",
    "                 metric = \"ROC\",\n",
    "                 trControl = ctrl0)\n",
    "svmFit0\n",
    "\n",
    "### Now fit the single 2008 test set\n",
    "ctrl00 <- trainControl(method = \"LGOCV\",\n",
    "                       summaryFunction = twoClassSummary,\n",
    "                       classProbs = TRUE,\n",
    "                       index = list(TestSet = 1:nrow(pre2008Data)))\n",
    "\n",
    "\n",
    "set.seed(476)\n",
    "svmFit00 <- train(allData[,fullSet], allData$Class,\n",
    "                  method = \"svmRadial\",\n",
    "                  tuneGrid = svmrGrid,\n",
    "                  preProc = c(\"center\", \"scale\"),\n",
    "                  metric = \"ROC\",\n",
    "                  trControl = ctrl00)\n",
    "svmFit00\n",
    "\n",
    "## Combine the two sets of results and plot\n",
    "\n",
    "grid0 <- subset(svmFit0$results,  sigma == svmFit0$bestTune$sigma)\n",
    "grid0$Model <- \"10-Fold Cross-Validation\"\n",
    "\n",
    "grid00 <- subset(svmFit00$results,  sigma == svmFit00$bestTune$sigma)\n",
    "grid00$Model <- \"Single 2008 Test Set\"\n",
    "\n",
    "plotData <- rbind(grid00, grid0)\n",
    "\n",
    "plotData <- plotData[!is.na(plotData$ROC),]\n",
    "xyplot(ROC ~ C, data = plotData,\n",
    "       groups = Model,\n",
    "       type = c(\"g\", \"o\"),\n",
    "       scales = list(x = list(log = 2)),\n",
    "       auto.key = list(columns = 1))\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
